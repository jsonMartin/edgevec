# W8.1: Binary Quantization Implementation

**Agent:** RUST_ENGINEER
**Estimated Time:** 8 hours
**Complexity:** HIGH
**Priority:** CRITICAL (Blocks W8.2-W8.7)

---

## MANDATE

Implement binary vector quantization for EdgeVec, compressing 768-dimensional f32 vectors into 96-byte binary representations with Hamming distance computation optimized for <50 CPU cycles per comparison.

**This is a CRITICAL PATH task. All subsequent Week 8 tasks depend on this completion.**

---

## STRATEGIC CONTEXT

**Week 8 Status:** Day 1 of 5 (Implementation phase)
**Phase:** Foundation - Quantization Infrastructure
**Architecture Gate:** GATE_2 (Planning → Implementation) - APPROVED

**Why Binary Quantization:**
1. Memory efficiency: 8x compression (768 f32 → 96 u8)
2. Search speed: Hamming distance is SIMD-friendly (<50 cycles vs >200 for f32 dot product)
3. WASM compatibility: No complex floating-point ops
4. Proven in binary_semantic_cache v1.0 (MIT licensed, salvageable)

**Performance Targets (from ARCHITECTURE.md Section 4.2):**
- Compression ratio: ≥8x (768 × 4 bytes → 96 bytes)
- Hamming distance: <50 CPU cycles per comparison (x86_64 AVX2)
- Memory alignment: 64-byte boundaries (SIMD requirement)
- Quantization latency: <1ms per vector (target for insert operations)

---

## REQUIRED CONTEXT

**Before coding, you MUST read:**

1. **`02_W8.1_CONTEXT_BUNDLE.md`** - Consolidated architecture/data layout excerpts
2. **`docs/architecture/ARCHITECTURE.md` Section 4.2** - Quantization requirements
3. **`docs/architecture/DATA_LAYOUT.md` Section 3** - Binary quantization memory layout

**Key Architecture Constraints:**
- WASM-compatible (no `std::arch` unless cfg-gated)
- no_std friendly (can use alloc)
- Deterministic (same input → same output, always)
- SIMD-ready (64-byte alignment for future AVX2 optimization)

---

## IMPLEMENTATION PLAN (Chain of Thought)

---

## PRE-IMPLEMENTATION: ENVIRONMENT PREREQUISITES

**Before starting implementation, verify/install required tools:**

### 1. Verify Rust Version
```bash
rustc --version
# Required: ≥1.70.0
# If below, run: rustup update stable
```

### 2. Install WASM Target (if missing)
```bash
rustup target list --installed | grep wasm32-unknown-unknown
# If no output, install:
rustup target add wasm32-unknown-unknown
# Verify:
rustup target list --installed | grep wasm32-unknown-unknown
# If still missing: STOP and escalate (requires rustup reinstall)
```

### 3. Install Code Coverage Tool
```bash
cargo tarpaulin --version 2>/dev/null || cargo install cargo-tarpaulin
# Windows fallback: cargo install cargo-llvm-cov
```

### 4. Verify All Prerequisites
```bash
echo "=== Prerequisite Check ==="
rustc --version && echo "✅ Rust OK"
rustup target list --installed | grep -q wasm32 && echo "✅ WASM target OK" || echo "❌ WASM missing"
cargo tarpaulin --version 2>/dev/null && echo "✅ Coverage tool OK" || echo "⚠️ Coverage missing"
echo "========================="
```

**Do NOT proceed if WASM target shows ❌**

---

## PRE-IMPLEMENTATION: BOOTSTRAP SEQUENCE

**Before implementing code, establish the test foundation to break circular dependency:**

### Bootstrap Step 1: Create Test Fixtures Directory
```bash
mkdir -p tests/fixtures
mkdir -p tests/unit
```

### Bootstrap Step 2: Generate Mock Vectors

Create `scripts/generate_mock_vectors.py`:
```python
import json
import random

random.seed(42)
vectors = {
    "all_positive": [1.0] * 768,
    "all_negative": [-1.0] * 768,
    "all_zeros": [0.0] * 768,
    "alternating": [1.0 if i % 2 == 0 else -1.0 for i in range(768)],
    "first_positive": [1.0 if i == 0 else -1.0 for i in range(768)],
    "random_seed_42": [random.uniform(-1.0, 1.0) for _ in range(768)]
}

with open("tests/fixtures/mock_vectors_768d.json", "w") as f:
    json.dump({"vectors": vectors}, f, indent=2)

print("Generated: tests/fixtures/mock_vectors_768d.json")
```

**Run:**
```bash
python scripts/generate_mock_vectors.py
ls tests/fixtures/mock_vectors_768d.json  # Must exist
```

### Bootstrap Step 3: Verify Fixture Format
```bash
# Verify JSON structure (if jq available)
jq '.vectors | keys' tests/fixtures/mock_vectors_768d.json
# Expected: ["all_negative", "all_positive", "all_zeros", "alternating", ...]
```

**This bootstrap breaks the circular dependency:** Tests use mock vectors (no quantization needed), real corpus generated in W8.2 (after quantization exists).

---

## PRE-IMPLEMENTATION: SALVAGE CODE VERIFICATION

**Before integrating salvaged code from binary_semantic_cache, verify compatibility:**

### Verification Step 1: Create Temporary Test Project
```bash
mkdir -p /tmp/salvage_verify && cd /tmp/salvage_verify
cargo init --lib
```

### Verification Step 2: Copy Salvaged Functions

Add to `src/lib.rs`:
```rust
// Adapted from binary_semantic_cache v1.0 (MIT License)
// Copyright (c) 2024 Matteo Panzeri
// Original: https://github.com/MatteoPossamai/binary_semantic_cache

/// Hamming distance between two byte slices
pub fn hamming_distance_single(a: &[u8], b: &[u8]) -> u32 {
    assert_eq!(a.len(), b.len());
    a.iter()
        .zip(b.iter())
        .map(|(x, y)| (x ^ y).count_ones())
        .sum()
}

/// Binarize f32 values and pack into bytes
pub fn binarize_and_pack_single(values: &[f32]) -> Vec<u8> {
    let num_bytes = (values.len() + 7) / 8;
    let mut result = vec![0u8; num_bytes];
    for (i, &v) in values.iter().enumerate() {
        if v > 0.0 {
            result[i / 8] |= 1 << (i % 8);
        }
    }
    result
}
```

### Verification Step 3: Compile for Multiple Targets
```bash
cargo check && echo "✅ Native OK" || echo "❌ Native FAILED"
cargo check --target wasm32-unknown-unknown && echo "✅ WASM OK" || echo "❌ WASM FAILED"
```

### Verification Step 4: Evaluate Results

**If BOTH pass:**
- ✅ Salvaged code is compatible - proceed with integration
- Cleanup: `rm -rf /tmp/salvage_verify`

**If Native passes but WASM fails:**
- ⚠️ Remove WASM-incompatible parts
- Implement WASM-safe alternative

**If Native fails:**
- ❌ STOP - implement from algorithm description, not salvaged code
- Document in handoff: "Salvaged code incompatible, implemented fresh"

---

### Step 1: Module Structure (30 min)

Create the following file structure:

```
src/quantization/
├── mod.rs          # Public API, re-exports, trait definitions
└── binary.rs       # BinaryQuantizer implementation
```

**mod.rs responsibilities:**
- Define `Quantizer` trait (if needed for polymorphism)
- Re-export `BinaryQuantizer` as public API
- Document module purpose and usage

**binary.rs responsibilities:**
- `BinaryQuantizer` struct
- `quantize()` method: f32[768] → u8[96]
- `hamming_distance()` function: u8[96] × u8[96] → u32
- Helper functions for bit packing

---

### Step 2: Data Structures (1 hour)

Define the core types:

```rust
/// Binary quantizer compressing f32 vectors to binary (u8) representation.
///
/// # Memory Layout
/// - Input: [f32; 768] (3072 bytes)
/// - Output: [u8; 96] (96 bytes, 64-byte aligned)
/// - Compression: 8x
///
/// # Example
/// ```
/// use edgevec::quantization::BinaryQuantizer;
///
/// let quantizer = BinaryQuantizer::new();
/// let vector: Vec<f32> = vec![0.5; 768];
/// let quantized = quantizer.quantize(&vector);
/// assert_eq!(quantized.len(), 96);
/// ```
#[repr(C, align(64))]  // 64-byte alignment for SIMD
pub struct BinaryQuantizer {
    // Configuration fields (if needed)
}

/// Quantized binary vector (96 bytes, 768 bits).
///
/// Each bit represents the sign of the original f32 value:
/// - Bit = 1 if f32 > 0.0
/// - Bit = 0 if f32 ≤ 0.0
#[repr(C, align(64))]
#[derive(Clone, Debug, PartialEq, Eq)]
pub struct QuantizedVector {
    data: [u8; 96],  // 768 bits packed into 96 bytes
}
```

**Design Decisions to Make:**
1. Should `BinaryQuantizer` be stateless or stateful?
   - Recommendation: Stateless (no training required for simple sign-based quantization)
2. Should `QuantizedVector` own data or be a newtype wrapper?
   - Recommendation: Own data (simpler ownership, WASM-friendly)

---

### Step 3: Quantization Algorithm (2 hours)

Implement the binarization function:

```rust
impl BinaryQuantizer {
    /// Quantize a 768-dimensional f32 vector to binary representation.
    ///
    /// # Algorithm
    /// For each dimension i in [0, 768):
    ///   - If vector[i] > 0.0, set bit i to 1
    ///   - Else, set bit i to 0
    ///
    /// Bits are packed into bytes in little-endian order:
    ///   - Byte 0 contains bits [0..8]
    ///   - Byte 1 contains bits [8..16]
    ///   - ...
    ///   - Byte 95 contains bits [760..768]
    ///
    /// # Performance
    /// Target: <1ms per vector (measured via cargo bench)
    ///
    /// # Example
    /// ```
    /// let quantizer = BinaryQuantizer::new();
    /// let vector = vec![1.0, -1.0, 0.5, -0.5]; // Simplified 4D example
    /// let quantized = quantizer.quantize(&vector);
    /// // Expected: First byte = 0b00000101 (bits 0 and 2 set)
    /// ```
    pub fn quantize(&self, vector: &[f32]) -> QuantizedVector {
        assert_eq!(vector.len(), 768, "Input must be 768-dimensional");

        let mut data = [0u8; 96];

        // TODO: Implement binarization
        // Hint: Can salvage from binary_semantic_cache encoder.rs:343-359
        // Remember to add attribution comment!

        QuantizedVector { data }
    }
}
```

**Salvage Opportunity:**
Check `binary_semantic_cache/src/quantization/encoder.rs` lines 343-359 for `binarize_and_pack_single`. If compatible, salvage with attribution:

```rust
// Adapted from binary_semantic_cache v1.0 (MIT License)
// Copyright (c) 2024 Matteo Panzeri
// Original: https://github.com/[user]/binary_semantic_cache/blob/main/src/quantization/encoder.rs#L343-L359
```

**Correctness Tests:**
- Zero vector → all bits 0
- Positive vector → all bits 1
- Mixed vector → correct bit pattern

---

### Step 4: Hamming Distance (2 hours)

Implement SIMD-ready Hamming distance:

```rust
impl QuantizedVector {
    /// Compute Hamming distance to another quantized vector.
    ///
    /// Hamming distance = number of differing bits.
    ///
    /// # Performance Target
    /// <50 CPU cycles per comparison (x86_64 AVX2)
    ///
    /// # Algorithm
    /// 1. XOR the two binary vectors (differing bits become 1)
    /// 2. Count the number of 1 bits (popcount)
    ///
    /// # SIMD Optimization
    /// Future optimization: Use AVX2 `_mm256_popcnt_epi64` for 4x speedup.
    /// Current: Portable implementation using u64 popcount.
    ///
    /// # Example
    /// ```
    /// let v1 = QuantizedVector { data: [0b11110000; 96] };
    /// let v2 = QuantizedVector { data: [0b00001111; 96] };
    /// assert_eq!(v1.hamming_distance(&v2), 96 * 8);  // All bits differ
    /// ```
    pub fn hamming_distance(&self, other: &Self) -> u32 {
        // TODO: Implement Hamming distance
        // Hint: Can salvage from binary_semantic_cache similarity.rs:286-292

        let mut distance = 0u32;

        for i in 0..96 {
            let xor = self.data[i] ^ other.data[i];
            distance += xor.count_ones();
        }

        distance
    }
}
```

**Salvage Opportunity:**
Check `binary_semantic_cache/src/similarity.rs` lines 286-292 for `hamming_distance_single`. If compatible, salvage with attribution.

**Performance Validation:**
```bash
cargo bench bench_hamming_distance
# Expected output:
# hamming_distance/96_bytes  time: [45.2 ns 46.1 ns 47.3 ns]
# Cycles (3.0 GHz CPU): ~138 cycles (FAIL - needs SIMD)
#
# After SIMD (future W9.3):
# hamming_distance/96_bytes  time: [12.3 ns 12.8 ns 13.5 ns]
# Cycles: ~38 cycles (PASS)
```

**Note:** <50 cycles target may not be met without SIMD. Document actual performance; optimization is W9.3 scope if >50 cycles.

**Optimization Trigger (P99 measurements):**
- If Hamming distance ≤50 cycles (P99): ✅ Target achieved
- If Hamming distance >50 but ≤75 cycles (P99): Consider loop unrolling (4x)
- If Hamming distance >75 but ≤100 cycles (P99): Try processing as u64 (12 iterations)
- If Hamming distance >100 cycles (P99): STOP - requires SIMD specialist intervention

**Note:** All cycle measurements are P99 (99th percentile) from `cargo bench` output.

**SIMD Escalation Protocol:**
If SIMD intrinsics fail to compile:
1. **STOP** - Do not proceed with broken SIMD
2. **Document** the exact error in handoff report
3. **Fallback** - Use portable implementation (already provided)
4. **Escalate** - Flag for W9.3 SIMD optimization sprint
5. **Continue** - Proceed with portable version (acceptable: <200 cycles baseline)

**Target SIMD Intrinsics (for W9.3):**
- **x86_64 (AVX2):** `_mm256_xor_si256`, `_mm_popcnt_u64`
- **ARM (NEON):** `veorq_u8`, `vcntq_u8`, `vaddvq_u8`
- **WASM:** Portable fallback (WASM SIMD deferred to W9.4)

**Performance Rollback Protocol:**
If benchmark shows >100 cycles per Hamming comparison:
1. **STOP** - Performance is unacceptable for production
2. **Revert** - `git stash` or `git checkout -- src/quantization/`
3. **Analyze** - Profile with `cargo flamegraph` to find bottleneck
4. **Document** - Record findings in handoff report under BLOCKERS
5. **Escalate** - Notify PLANNER: "W8.1 blocked on performance, need BENCHMARK_SCIENTIST"
6. **DO NOT** proceed to W8.2 with >100 cycle Hamming distance

---

### Step 5: Unit Tests (2 hours)

**Test File Location:**
```bash
# Create directory structure first (idempotent)
mkdir -p tests/unit

# Create test file
touch tests/unit/test_quantization.rs

# Add module declaration (create mod.rs if needed)
echo "mod test_quantization;" >> tests/unit/mod.rs
```

Create comprehensive test suite in `tests/unit/test_quantization.rs`:

```rust
#[cfg(test)]
mod tests {
    use edgevec::quantization::BinaryQuantizer;

    #[test]
    fn test_quantize_zero_vector() {
        let quantizer = BinaryQuantizer::new();
        let zero = vec![0.0f32; 768];
        let quantized = quantizer.quantize(&zero);

        // All bits should be 0 (0.0 ≤ 0.0)
        assert_eq!(quantized.data, [0u8; 96]);
    }

    #[test]
    fn test_quantize_positive_vector() {
        let quantizer = BinaryQuantizer::new();
        let positive = vec![1.0f32; 768];
        let quantized = quantizer.quantize(&positive);

        // All bits should be 1 (1.0 > 0.0)
        assert_eq!(quantized.data, [0xFFu8; 96]);
    }

    #[test]
    fn test_quantize_mixed_vector() {
        let quantizer = BinaryQuantizer::new();
        let mut mixed = vec![-1.0f32; 768];
        mixed[0] = 1.0;  // First bit should be 1
        mixed[8] = 1.0;  // Ninth bit should be 1 (second byte, bit 0)

        let quantized = quantizer.quantize(&mixed);

        assert_eq!(quantized.data[0], 0b00000001);  // Bit 0 set
        assert_eq!(quantized.data[1], 0b00000001);  // Bit 8 set
    }

    #[test]
    fn test_hamming_distance_identical() {
        let quantizer = BinaryQuantizer::new();
        let vec = vec![0.5f32; 768];
        let q1 = quantizer.quantize(&vec);
        let q2 = quantizer.quantize(&vec);

        assert_eq!(q1.hamming_distance(&q2), 0);
    }

    #[test]
    fn test_hamming_distance_opposite() {
        let q1 = QuantizedVector { data: [0x00u8; 96] };
        let q2 = QuantizedVector { data: [0xFFu8; 96] };

        assert_eq!(q1.hamming_distance(&q2), 768);  // All 768 bits differ
    }

    #[test]
    fn test_hamming_distance_symmetric() {
        let q1 = QuantizedVector { data: [0xAAu8; 96] };  // 10101010...
        let q2 = QuantizedVector { data: [0x55u8; 96] };  // 01010101...

        assert_eq!(q1.hamming_distance(&q2), q2.hamming_distance(&q1));
    }

    #[test]
    fn test_quantize_deterministic() {
        let quantizer = BinaryQuantizer::new();
        let vec = vec![0.123f32; 768];

        let q1 = quantizer.quantize(&vec);
        let q2 = quantizer.quantize(&vec);

        assert_eq!(q1, q2);  // Must be deterministic
    }

    #[test]
    fn test_alignment() {
        let q = QuantizedVector { data: [0u8; 96] };
        let ptr = &q as *const QuantizedVector as usize;

        assert_eq!(ptr % 64, 0, "QuantizedVector must be 64-byte aligned");
    }
}
```

**Coverage Target:** 100% of public API

**Verification:**
```bash
cargo tarpaulin --out Html --output-dir coverage
# Open coverage/index.html, verify quantization module at 100%
```

---

## DELIVERABLES CHECKLIST

**Files to Create:**
- [ ] `src/quantization/mod.rs` (module root)
- [ ] `src/quantization/binary.rs` (implementation)
- [ ] `tests/unit/test_quantization.rs` (unit tests)

**Code Quality:**
- [ ] Rustdoc comments on all public items
- [ ] Examples in doc comments (tested via `cargo test --doc`)
- [ ] Attribution for salvaged code
- [ ] Zero clippy warnings
- [ ] Formatted via `cargo fmt`

**Testing:**
- [ ] All unit tests pass (`cargo test quantization`)
- [ ] Coverage ≥100% of public API
- [ ] Property test: Determinism (`quantize(v) == quantize(v)`)
- [ ] Property test: Bounds checking (`distance ≤ 768`)

**Performance:**
- [ ] Benchmark created: `benches/bench_quantization.rs`
- [ ] Hamming distance measured (document actual cycles, even if >50)

**Integration:**
- [ ] Compiles: `cargo build --release`
- [ ] Integrates with existing HNSW (no breaking changes)
- [ ] WASM-compatible: `cargo build --target wasm32-unknown-unknown`

---

## ANTI-HALLUCINATION CLAMPS

**DO NOT:**
1. Assume existing code structure without reading it
2. Implement Product Quantization (deferred to W9.5)
3. Optimize for SIMD without AVX2 feature gate (optimization is W9.3)
4. Use `unsafe` without written safety proof
5. Copy code without attribution

**DO:**
1. Quote ARCHITECTURE.md for all performance targets
2. Reference DATA_LAYOUT.md for memory layouts
3. Read existing `src/` structure before creating modules
4. Test alignment explicitly (use `std::mem::align_of`)
5. Document actual performance (even if below target)

---

## VERIFICATION COMMANDS

**After implementation, run these commands in order:**

```bash
# 1. Format check
cargo fmt --check
# Expected: No output (already formatted)

# 2. Lint check
cargo clippy -- -D warnings
# Expected: Exit code 0 (no warnings)

# 3. Build check
cargo build --release
# Expected: Exit code 0 (compiles)

# 4. Unit tests
cargo test quantization
# Expected: All tests pass

# 5. Doc tests
cargo test --doc
# Expected: All doc examples pass

# 6. Coverage
cargo tarpaulin --packages edgevec --out Stdout | grep quantization
# Expected: Coverage: 100.00%

# 7. Benchmark
cargo bench bench_hamming_distance
# Expected: Output shows cycles (document result)

# 8. WASM check
cargo build --target wasm32-unknown-unknown
# Expected: Exit code 0 (WASM-compatible)
```

**All 8 commands must pass before W8.1 is complete.**

---

## ACCEPTANCE CRITERIA (03_W8.1_ACCEPTANCE_CHECKLIST.md)

Refer to `03_W8.1_ACCEPTANCE_CHECKLIST.md` for the complete binary pass/fail checklist.

**Critical Criteria (Must Pass):**
1. Binary quantization: 768D → 96 bytes ✓
2. Hamming distance implemented ✓
3. All tests pass ✓
4. Zero clippy warnings ✓
5. 64-byte alignment verified ✓

---

## HANDOFF PROTOCOL

**Upon completion:**
1. Run all 8 verification commands
2. Document results in `05_DAY_1_HANDOFF_TEMPLATE.md`
3. Commit code: `git add . && git commit -m "W8.1: Binary Quantization implementation"`
4. Tag: `git tag w8.1-complete`
5. Notify PLANNER: "W8.1 complete, [X]/10 acceptance criteria passed, [Y] cycles Hamming distance"

**If blocked:**
- Escalate to PLANNER if >8 hours elapsed
- Document blocker in handoff report
- Propose contingency (descope, extend timeline, etc.)

---

## REFERENCE MATERIALS

**Salvage Sources (MIT Licensed):**
- `binary_semantic_cache/src/quantization/encoder.rs` (binarization)
- `binary_semantic_cache/src/similarity.rs` (Hamming distance)

**Architecture:**
- `docs/architecture/ARCHITECTURE.md` Section 4.2
- `docs/architecture/DATA_LAYOUT.md` Section 3

**Context:**
- `02_W8.1_CONTEXT_BUNDLE.md` (consolidated excerpts)

---

**Good luck, RUST_ENGINEER! This is the foundation of Week 8. Execute with precision.**

**END OF W8.1 IMPLEMENTATION PROMPT**
