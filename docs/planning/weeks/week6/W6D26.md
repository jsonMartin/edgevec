# W6D26: Quantization Architecture (Monday)

**Goal:** Define the Quantization Strategy and update System Architecture.

## Context
The "W5.5 Scaling Failure" proved `f32` is too slow/large. We pivot to SQ8.
Today is pure design and cleanup. NO CODE until Architecture is approved.

## Tasks

### 1. Architecture Update (W6.1)
- **File:** `edgevec/docs/architecture/ARCHITECTURE.md`
    - Deprecate `f32` as *primary* storage.
    - Introduce `QuantizedVector<N>` (likely `[u8; N]`).
    - Define `ScalarQuantizer` component.
- **File:** `edgevec/docs/architecture/DATA_LAYOUT.md`
    - Update `VectorStorage` layout.
    - New layout:
        ```text
        VectorStorage {
            quantized: Arena<u8>, // Contiguous, cache-friendly
            original: Option<Arena<f32>>, // For re-ranking (optional)
        }
        ```
    - Define memory budget:
        - **Target:** 1M vectors * 768 dimensions * 1 byte = **768 MB** (< 1GB Budget).
        - *Note:* 1536 dimensions (OpenAI) would be 1.5 GB, which exceeds the strict 1GB limit for this sprint. We will validate with 768d first.

### 2. Interface Definition
- Define the `ScalarQuantizer` trait in `src/quantization/mod.rs` (conceptual).
    - `train(vectors: &[&[f32]]) -> Quantizer`
    - `quantize(vector: &[f32]) -> Vec<u8>`
    - `reconstruct(quantized: &[u8]) -> Vec<f32>`

### 3. Cleanup
- Identify code to delete/archive from `f32` era.

## Deliverables
- [ ] Updated `ARCHITECTURE.md` [PREREQUISITE FOR CODE]
- [ ] Updated `DATA_LAYOUT.md` [PREREQUISITE FOR CODE]

## Verification
- HOSTILE_REVIEWER must sign off on the new Memory Budget.

