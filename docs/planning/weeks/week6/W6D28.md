# W6D28: Storage Integration (Wednesday)

**Goal:** Refactor `VectorStorage` to hold `u8` vectors.

## Context
We need to change the engine from a "Float Store" to a "Byte Store".

## Tasks

### 1. Refactor VectorStorage (W6.3)
- **File:** `src/storage/mod.rs`
- **Change:**
    - `data: Arena<f32>` -> `quantized_data: Arena<u8>`.
    - Add `metadata: QuantizerMetadata`.
- **Feature:** Dual-Storage
    - Add `full_precision: Option<Arena<f32>>`.
    - Config flag: `store_original: bool`.

### 2. Update Insert Pipeline
- `insert(vec: &[f32])`:
    1. Calculate/Update Quantizer stats (if dynamic) - *Wait, simple SQ8 requires a training phase or fixed bounds.*
    - *Pivot Strategy:* For online updates, we need fixed bounds (e.g., -1.0 to 1.0 for Cosine) or adaptive?
    - *Decision:* **Assume Normalized Vectors (-1.0 to 1.0)** for now. Easy mapping to 0..255.
    2. Quantize `f32` -> `u8`.
    3. Store `u8`.
    4. Store `f32` (optional).

### 3. Pre-Quantized Loading
- **Method:** `insert_quantized(vectors: &[u8])`
- **Rationale:** Critical for bulk loading 1M vectors without burning CPU on re-quantization.
- **Flow:** Direct copy to `quantized_data` arena.


## Deliverables
- [ ] `VectorStorage` supports `u8`.
- [ ] `insert` pipeline quantizes on the fly.

## Verification
- `test_storage_integrity`: Can we read back what we wrote?

